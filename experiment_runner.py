import torch
import logging
import numpy as np
import os
import pandas as pd

from WeightEnv import WeightEnv


def run_experiment_3(algo='er_ddpg', train=True, episodes=1000, max_steps=100, device='cuda'):
    # from WeightDemo import WeightEnv
    from baseline_experiments import (
        # build_er_ddpg_agent,
        build_ddpg_agent,
        build_td3_agent,
        build_ppo_agent,
        build_sac_agent,
        build_td3_bc_agent, build_cql_agent,
        # build_emotion_td3_agent,
        build_emotion_sac_agent,
        build_fuzzy_agent,
        build_ppol_agent, build_rls_pid_agent
    )
    from DifferentModules.td3_agent import train_td3
    from DifferentModules.td3_bc_agent import train_td3_bc
    from DifferentModules.cql_agent import train_cql
    from DifferentModules.PPOL import train_ppo_lagrangian
    from DifferentModules.rls_pidagent import train_rls_pid
    from DifferentModules.ppo_agent import train_ppo
    from DifferentModules.sac_agent import train_sac
    # from Emotion_TD3 import train_emotion_td3
    import os
    import numpy as np

    env = WeightEnv()
    algo_builders = {
        # 'er_ddpg': build_er_ddpg_agent,
        'ddpg': build_ddpg_agent,
        'td3': build_td3_agent,
        'td3_bc': build_td3_bc_agent,
        'ppo': build_ppo_agent,
        'sac': build_sac_agent,
        'cql': build_cql_agent,
        'ppol': build_ppol_agent,
        'rls_pid': build_rls_pid_agent,
        # 'emotion_td3': build_emotion_td3_agent,
        'emotion_sac': build_emotion_sac_agent,
        'fuzzy': build_fuzzy_agent  # âœ… æ·»åŠ  fuzzy agent
    }
    assert algo in algo_builders, f"Unsupported algorithm: {algo}"
    agent = algo_builders[algo](env, device=device)
    env.attach_agent(agent)

    model_dir = os.path.join("saved_models", algo)
    os.makedirs(model_dir, exist_ok=True)
    model_path = os.path.join(model_dir, f"{algo}_final.pth")
    log_prefix = f"exp3_{algo}"

    if train and algo != 'fuzzy':  # æ¨¡ç³Šæ§åˆ¶ä¸è®­ç»ƒ
        print(f"ï¿½ï¿½ Start training {algo.upper()}...")
        if algo == 'ddpg':
            from DifferentModules.ddpg_agent import train_ddpg
            train_ddpg(env, agent, episodes=episodes, max_steps=max_steps, log_prefix=log_prefix)
            agent.save(model_path)

        elif algo == 'td3':
            train_td3(env=env, agent=agent, episodes=episodes, max_steps=max_steps, log_prefix=log_prefix)
            agent.save(model_path)

        elif algo == 'td3_bc':
            train_td3_bc(env=env, agent=agent, episodes=episodes, max_steps=max_steps, log_prefix=log_prefix)
            agent.save(model_path)

        elif algo == 'ppo':
            train_ppo(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
                      log_prefix=log_prefix, model_path=model_path)

        elif algo == 'sac':
            train_sac(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
                      log_prefix=log_prefix, model_path=model_path)

        elif algo == 'cql':
            train_cql(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
                      log_prefix=log_prefix, model_path=model_path)

        elif algo == 'ppol':
            train_ppo_lagrangian(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
                                 log_prefix=log_prefix, model_path=model_path)

        elif algo == 'rls_pid':
            train_rls_pid(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
                          log_prefix=log_prefix, model_path=model_path)

        # elif algo == 'emotion_td3':
        #     train_emotion_td3(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
        #                       log_prefix=log_prefix, model_path=model_path)

        elif algo == 'emotion_sac':
            from DifferentModules.ERL_Fill_agent import train_emotion_sac
            train_emotion_sac(env=env, agent=agent, episodes=episodes, max_steps=max_steps,
                              log_prefix=log_prefix, model_path=model_path)
        else:
            print("No such module")

        print(f"âœ… Training complete. Model saved at: {model_path}")
        avg_reward = 0
    else:
        print(f"ï¿½ï¿½ Start testing {algo.upper()}...")
        if algo != 'fuzzy' and not os.path.exists(model_path):
            raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        test_episodes = 200
        if algo != 'fuzzy':
            agent.load(model_path)
            test_episodes = 100
            print(f"âœ… æ¨¡å‹æƒé‡å·²åŠ è½½ï¼š{model_path}")

        total_reward = 0

        test_log_path = os.path.join("logs", f"test_result_{algo}.log")
        os.makedirs("logs", exist_ok=True)

        def extract_scalar(v):
            if isinstance(v, np.ndarray):
                if v.size == 1:
                    return v.item()
                elif v.ndim == 0:
                    return float(v)
                else:
                    raise ValueError(f"âŒ éæ ‡é‡ ndarray: {v} (shape={v.shape})")
            return float(v)

        with open(test_log_path, "w", encoding="utf-8") as f_log:
            for ep in range(test_episodes):
                state = env.reset()
                episode_reward = 0
                try:
                    for step in range(max_steps):
                        if algo in ['ppo', 'sac']:
                            action = agent.act(state, deterministic=True) if hasattr(agent,
                                                                                     'act') else agent.select_action(
                                state)
                        else:
                            action = agent.act(state)

                        # âœ… ä¿®å¤ fuzzy è¿”å› dict é”™è¯¯
                        if isinstance(action, dict):
                            action_dict = action
                        else:
                            action_dict = {k: extract_scalar(v) for k, v in zip(env.bounds.keys(), action)}

                        next_state, reward, done, info = env.step(action_dict)

                        state = next_state
                        episode_reward += reward
                        if done:
                            break

                    slow_weight = info["action"].get("slow_weight", 0.0)
                    log_str = (
                        f"[{algo.upper()} | Episode {ep:04d}] "
                        f"TotalReward: {episode_reward:.2f} | "
                        f"WeightErr: {info['weight_error']:.2f}g | "
                        f"Time: {info['total_time']:.2f}s | "
                        f"SlowWeight: {slow_weight:.2f}g"
                    )
                    print(f"ï¿½ï¿½ Test Episode {ep + 1}: {episode_reward:.2f}")
                    f_log.write(log_str + "\n")

                except Exception as e:
                    error_msg = f"[{algo.upper()} | Episode {ep:04d}] âŒ æµ‹è¯•å‡ºé”™: {e}"
                    print(error_msg)
                    f_log.write(error_msg + "\n")

                total_reward += episode_reward

            avg_reward = total_reward / test_episodes
            summary = f"\nâœ… Avg Test Reward for {algo.upper()}: {avg_reward:.2f}\n"
            print(summary)
            f_log.write(summary)

    return model_path, avg_reward


if __name__ == "__main__":
    # === å…¨å±€é…ç½® ===
    device = 'cuda'
    train_mode = True        # âœ… True å¼€å§‹è®­ç»ƒï¼ŒFalse å¼€å§‹æµ‹è¯•
    experiment_id = 3        # âœ… è®¾ç½®ä¸º 1ã€2ã€3ã€4 é€‰æ‹©å®éªŒç»„
    # selected_algo = 'er_ddpg'  # å®éªŒ3ã€4ä¸“ç”¨
    episodes = 5
    max_steps = 50
    test_episodes = 10
    # # selected_algo = 'ddpg'
    # # selected_algo = 'td3'
    # # selected_algo = 'ppo'
    # selected_algo = 'sac'
    use_offline_sim = 1 #1-é‡‡æ ·ç¦»çº¿ä»¿çœŸï¼Œ0-é‡‡ç”¨æ¿è½½ä»¿çœŸï¼Œ2-çœŸå®ç³»ç»Ÿè®­ç»ƒ

    # === å®éªŒä¸€ï¼šæƒ…æ„Ÿæœºåˆ¶å¯¹ç…§ç»„ ===
    # === å®éªŒä¸€ï¼šæƒ…æ„Ÿæœºåˆ¶å¯¹ç…§ç»„ï¼ˆ5ç»„å®éªŒï¼‰ ===
    if experiment_id == 1:
        emotion_modes = ['none', 'simple', 'transformer']  # Baselineã€Simpleã€Transformer
        # algo_list = ['sac']  # æœ¬å®éªŒåªè·‘SAC
        # results = []
        #
        # # === å®šä¹‰5ç»„å®éªŒé…ç½® ===
        # experiment_configs = [
        #     {'name': 'Baseline', 'mode': 'none', 'lambda_emo': 0.0},
        #     {'name': 'Simple', 'mode': 'simple', 'lambda_emo': 0.05},
        #     {'name': 'Transformer', 'mode': 'transformer', 'lambda_emo': 0.05},
        #     {'name': 'Transformer-High', 'mode': 'transformer', 'lambda_emo': 0.2},
        #     {'name': 'Transformer-Low', 'mode': 'transformer', 'lambda_emo': 0.01},
        # ]
        #
        # for config in experiment_configs:
        #     mode = config['mode']
        #     lambda_emo = config['lambda_emo']
        #     group_name = config['name']
        #
        #     print(f"\n=== Running Group: {group_name} | Mode: {mode} | Î»_emo: {lambda_emo} ===")
        #
        #     # === ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒ ===
        #     _ = run_experiment_1(
        #         episodes=episodes,
        #         max_steps=max_steps,
        #         device=device,
        #         env_mode='sim',
        #         emotion_modes=[mode],
        #         algo_list=algo_list,
        #         train=True,
        #         lambda_emo=lambda_emo,
        #         log_prefix=f"{group_name}_train"
        #     )
        #
        #     # === ç¬¬äºŒæ­¥ï¼šæµ‹è¯• ===
        #     test_results = run_experiment_1(
        #         episodes=test_episodes,
        #         max_steps=max_steps,
        #         device=device,
        #         env_mode='sim',
        #         emotion_modes=[mode],
        #         algo_list=algo_list,
        #         train=False,
        #         lambda_emo=lambda_emo,
        #         log_prefix=f"{group_name}_test"
        #     )
        #
        #     # ç»“æœä¿å­˜
        #     for algo, mode_result, avg_reward in test_results:
        #         results.append((group_name, algo, mode_result, avg_reward))
        #
        # # === æœ€ç»ˆå®éªŒç»“æœè¾“å‡º ===
        # print("\n=== âœ… å®éªŒä¸€ï¼ˆEmotion Mechanism Ablationï¼‰5ç»„å¯¹ç…§ç»“æœ ===")
        # for group, algo, mode, reward in results:
        #     print(f"[Group: {group} | Algo: {algo.upper()} | Mode: {mode}] â†’ AvgTestReward: {reward:.2f}")
    # if experiment_id == 1:
    #     # emotion_modes = ['none', 'simple', 'transformer']
    #     # emotion_modes = ['simple', 'transformer']
    #     emotion_modes = ['transformer']
    #     # algo_list = ['ddpg', 'td3', 'sac']  # âœ… 3ç§ç®—æ³•
    #     algo_list = [ 'sac']  # âœ… 3ç§ç®—æ³•
    #     results = []
    #     lambda_emo = 0.01 #lambda_emo = 0.01, lambda_emo=0.05, lambda_emo=0.1
    #
    #     for algo in algo_list:
    #         for mode in emotion_modes:
    #             print(f"\n=== Running Algo: {algo.upper()} | Emotion Mode: {mode.upper()} ===")
    #
    #             # ç¬¬ä¸€æ­¥ï¼šè®­ç»ƒ + ä¿å­˜æ¨¡å‹
    #             _ = run_experiment_1(
    #                 episodes=episodes,
    #                 max_steps=max_steps,
    #                 device=device,
    #                 env_mode='sim',
    #                 emotion_modes=[mode],  # âœ… åªè®­ç»ƒè¿™ä¸ª mode
    #                 algo_list=[algo],  # âœ… åªè®­ç»ƒè¿™ä¸ª algo
    #                 train=True,  # âœ… è®­ç»ƒ
    #                 lambda_emo = lambda_emo
    #             )
    #
    #             # ç¬¬äºŒæ­¥ï¼šæµ‹è¯• + åŠ è½½æ¨¡å‹
    #             test_results = run_experiment_1(
    #                 episodes=test_episodes,
    #                 max_steps=max_steps,
    #                 device=device,
    #                 env_mode='sim',
    #                 emotion_modes=[mode],  # âœ… åªæµ‹è¯•è¿™ä¸ª mode
    #                 algo_list=[algo],  # âœ… åªæµ‹è¯•è¿™ä¸ª algo
    #                 train=False,  # âœ… æµ‹è¯•
    #                 lambda_emo = lambda_emo
    #             )
    #
    #             results.extend(test_results)
    #
    #     # === æœ€ç»ˆå®éªŒä¸€ç»“æœè¾“å‡º ===
    #     print("\n=== âœ… å®éªŒä¸€ï¼ˆEmotion Mechanism Ablationï¼‰ç»“æœå¯¹æ¯” ===")
    #     for algo, mode, reward in results:
    #         print(f"[{algo.upper()} | {mode}] å¹³å‡æµ‹è¯•å¥–åŠ±: {reward:.2f}")

    # # === å®éªŒäºŒï¼šåˆ†é˜¶æ®µé¢„è®­ç»ƒç»“æ„å¯¹æ¯” ===
    # elif experiment_id == 2:
    #     print("\n=== Running Multi-Stage Pretraining Evaluation ===")
    #     run_experiment_2(device=device, train=train_mode, use_off_sim=use_offline_sim)

    # # === å®éªŒä¸‰ï¼šå¼ºåŒ–å­¦ä¹ ç®—æ³•å¯¹æ¯” ===
    # elif experiment_id == 3:
    #     print(f"\n=== Running Algorithm Comparison for All Methods ===")
    #     algo_list = ['er_ddpg', 'ddpg', 'td3', 'ppo', 'sac','emotion_td3','emotion_sac']
    #     # algo_list = ['emotion_sac','sac']
    #     # algo_list = ['emotion_sac']
    #     results = []

    #     for algo in algo_list:
    #         print(f"\n>>> ğŸš€ Start {algo.upper()} Training & Testing")
    #         model_path, test_reward = run_experiment_3(
    #             algo=algo,
    #             train=train_mode,
    #             episodes=episodes,
    #             max_steps=max_steps,
    #             device=device
    #         )
    #         results.append((algo, test_reward))

    #     print("\n=== âœ… å®éªŒä¸‰ç»“æœå¯¹æ¯” ===")
    #     for algo, reward in results:
    #         print(f"[{algo.upper()}] å¹³å‡æµ‹è¯•å¥–åŠ±: {reward:.2f}")

    # === å®éªŒä¸‰ï¼šå¼ºåŒ–å­¦ä¹ ç®—æ³•å¯¹æ¯” ===
    elif experiment_id == 3:
        print(f"\n=== Running Algorithm Comparison for All Methods ===")
        # algo_list = ['er_ddpg', 'ddpg', 'td3','td3_bc','ppo', 'sac', 'cql', 'ppol', 'rls_pid', 'emotion_td3','emotion_sac', 'fuzzy']  # âœ… åŒ…å«æ¨¡ç³Šæ§åˆ¶
        algo_list = ['td3','sac','ppo','ddpg','td3_bc','rls_pid', 'cql','emotion_sac', 'fuzzy']  # âœ… åŒ…å«æ¨¡ç³Šæ§åˆ¶
        results = []

        for algo in algo_list:
            print(f"\n>>> ïš€ Start {algo.upper()} Training & Testing")
            model_path, test_reward = run_experiment_3(
                algo=algo,
                train=train_mode,
                episodes=episodes,
                max_steps=max_steps,
                device=device
            )
            results.append((algo, test_reward))

        print("\n=== âœ… å®éªŒä¸‰ç»“æœå¯¹æ¯” ===")
        for algo, reward in results:
            print(f"[{algo.upper()}] å¹³å‡æµ‹è¯•å¥–åŠ±: {reward:.2f}")

    # # === å®éªŒå››ï¼šå¤šå·¥å†µå¯¹æ¯”å®éªŒ ===
    # elif experiment_id == 4:
    #     print(f"\n=== Running Multi-Condition Comparison Experiment ===")
    #
    #     # é€‰æ‹©è¦è·‘çš„ç®—æ³•
    #     algo_list = ['emotion_sac']  # å¯ä»¥ä»»é€‰
    #
    #     for algo in algo_list:
    #         print(f"\n=== ğŸš€ Running {algo.upper()} for Multi-Condition ===")
    #         run_experiment_4(
    #             train=True,  # True=è®­ç»ƒ+æµ‹è¯•ï¼ŒFalse=åªæµ‹è¯•
    #             episodes=episodes,
    #             max_steps=max_steps,
    #             device=device,
    #             algo=algo  # âœ… ä¼ å…¥æŒ‡å®šç®—æ³•
    #         )

    else:
        print("âŒ Unsupported experiment ID. Please set experiment_id = 1, 2, 3, or 4.")